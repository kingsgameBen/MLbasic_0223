{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "鐵達尼號.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMu5AIArSuNiMY6ivkS0Vxw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kingsgameBen/MLbasic_0223/blob/main/%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4shoWpsDui7z"
      },
      "source": [
        "註冊Kaggle\n",
        "\n",
        "sign in with google: ReZeroBen\n",
        "\n",
        "\n",
        "資料預處理\n",
        "\n",
        "(Sibsp: 手足 siblings 、配偶 spouse)\\\n",
        "(Parch: 父母Parents、兒女child) \\\n",
        "(Fare: 船費)\\\n",
        "(Embarked: 登船口岸 \n",
        "C=法國Cherbourg, Q=愛爾蘭Queenstown, S=英國Southampton)\\\n",
        "[ https://chtseng.wordpress.com/2017/12/24/kaggle-titanic%E5%80%96%E5%AD%98%E9%A0%90%E6%B8%AC-1/ ]\n",
        "\n",
        "欄位先分成兩種\n",
        "  1. 類別型：艙等 Pclass、Name(mid: Mr. 、Mrs. ..)、Sex(直接換成2值型)、艙號 Cabin(首字母$1^{st}$: 區域)、Embarked登船港口\n",
        "\n",
        "  2. 數值型: 年紀age、SibSp、Parch、ticket(share同張票)、Fare\n",
        "\n",
        "\n",
        "1. 填補缺失值：=> 最可能的數值 \\\n",
        "從可能的欄位推敲、\\\n",
        "類別：該欄位最常出現的值\n",
        "\n",
        "數值：=> ex:薪資->中位數\n",
        "  - 眾數\n",
        "  - 平均數(單位:數值、錢、收入...把大家削成一樣的!)\n",
        "  - $\\ast$中位數$\\ast$(單位：人數、數量、計數...)\n",
        "\n",
        "一起填 pandas.concat\n",
        "[ https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html ]\n",
        "\n",
        "axis 雙向型的api\n",
        "\n",
        "axis=0 縱向連接 \\\n",
        "axis=1 橫向型連接(擴增欄位)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJwf8gQguhF_"
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "url = \"https://github.com/kingsgameBen/MLbasic_0223/raw/main/titanic/train.csv\"\n",
        "urlretrieve(url, \"train.csv\")\n",
        "url = \"https://github.com/kingsgameBen/MLbasic_0223/raw/main/titanic/test.csv\"\n",
        "urlretrieve(url, \"test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw3NjUEK2iDG"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\", encoding=\"utf-8\")\n",
        "test_df = pd.read_csv(\"test.csv\", encoding=\"utf-8\")\n",
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55_lCQRP3vMU"
      },
      "source": [
        "datas = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
        "datas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao9tWefq-dXA"
      },
      "source": [
        "(dataframe.sum())[ https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sum.html ]\n",
        "\n",
        "把有缺的值做一個篩選\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1J-oFfa9-87"
      },
      "source": [
        "# .count()數欄位 .sum()可以縱向橫向相加\n",
        "s = datas.isna().sum()\n",
        "# Series[True/False]\n",
        "# s[s > 0].sort_values()\n",
        "s[s > 0].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy9vSITR_OGR"
      },
      "source": [
        "datas = datas.drop([\"PassengerId\", \"Survived\"], axis=1)\n",
        "# 數值類型：中位數\n",
        "# median() 取datas各個非文字欄位的中位數\n",
        "# median()排除Pclass欄位, 是因為該欄位的值1, 2, 3是代表等級, 而不是數量\n",
        "# fillna()會把datas各個欄位裡, 有取得median的欄位(age、Fare)空值都填上\n",
        "med = datas.median().drop(\"Pclass\")\n",
        "print(med)\n",
        "datas = datas.fillna(med)\n",
        "\n",
        "s = datas.isna().sum()\n",
        "s[s > 0].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODF5jvxvuHoe"
      },
      "source": [
        "DataFrame.idxmax() \\\n",
        "[ https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.idxmax.html ] \\\n",
        "對該欄位值分類計數後, 取計數值最大的 => 最常出現的眾數\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuDgSf6VArlp"
      },
      "source": [
        "# 類別類型： 找最常出現,不可以取中位數\n",
        "most = datas[\"Embarked\"].value_counts().idxmax()\n",
        "datas[\"Embarked\"] = datas[\"Embarked\"].fillna(most)\n",
        "\n",
        "s = datas.isna().sum()\n",
        "s[s > 0].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ritBCPLaAeNV"
      },
      "source": [
        "# 處理 Cabin \n",
        "def cabin(s):\n",
        "    if pd.isna(s):\n",
        "        return None\n",
        "    else:\n",
        "        return s[0]\n",
        "datas[\"Cabin\"] = datas[\"Cabin\"].apply(cabin)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUGJZaGjBGmz"
      },
      "source": [
        "# 處理 Name\n",
        "def name(s):\n",
        "    mid = s.split(\",\")[-1].split(\".\")[0].strip()\n",
        "    return mid\n",
        "# 去除name裡稀少的樣本\n",
        "count = datas[\"Name\"].apply(name).value_counts()\n",
        "reserved = count[:4].index\n",
        "# print(count, reserved)\n",
        "def name_reserved(s):\n",
        "    mid = s.split(\",\")[-1].split(\".\")[0].strip()\n",
        "    if mid in reserved:\n",
        "        return mid\n",
        "    else:\n",
        "        return None\n",
        "datas[\"Name\"] = datas[\"Name\"].apply(name_reserved)\n",
        "\n",
        "datas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0W2IMhWDowF"
      },
      "source": [
        "# 處理 Ticket\n",
        "dic = datas[\"Ticket\"].value_counts()\n",
        "def ticket(t):\n",
        "    return dic[t]\n",
        "datas[\"Ticket\"] = datas[\"Ticket\"].apply(ticket)\n",
        "datas[\"Ticket\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26Tktf06DXpQ"
      },
      "source": [
        "get_dummies[ https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html ]\n",
        "產生虛擬欄位 \\\n",
        "將該欄位row裡的值分類轉換成虛擬欄位,就可以做計數 \\\n",
        "\n",
        "ex: \\\n",
        "Sex: male、female $\\Downarrow$ \\\n",
        "Sex_male: 0, 1, 1, 0, 0, 0 ..... \\\n",
        "Sex_female: 1, 0, 0, 1, 1, 1...\n",
        "\n",
        "\n",
        "### $\\color {red}{One-Hot encoding 獨熱編碼}$\n",
        "當特徵不是連續值,而是分類值時,為了比大小,要把值轉換成 \\\n",
        "數個是非題: 只有0, 1\n",
        "\n",
        "~{Pclass欄位,在這裏用偷懶的方式,不做one-hot encoding}~\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm7UkZ2KDbgy"
      },
      "source": [
        "datas = pd.get_dummies(datas)\n",
        "datas = pd.get_dummies(datas, columns=[\"Pclass\"])\n",
        "datas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDh1D8wCEXLc"
      },
      "source": [
        "# 是否新增欄位, 是靠觀察欄位之間的關係, 不斷嘗試是否能提高預測準確率,得到的結果\n",
        "# 新增欄位：將手足配偶 旁系欄位 ＋ 雙親兒女 直系欄位 結合成 家族欄位\n",
        "# (親屬或家人一起可以互相幫助)\n",
        "datas[\"Family\"] = datas[\"SibSp\"]+datas[\"Parch\"]\n",
        "datas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTAvGru1K6gI"
      },
      "source": [
        "隨機森林\n",
        "\n",
        "Ensemble集成式的演算法\n",
        "\n",
        "(RandomForestClassifier)[ https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html ]\n",
        "\n",
        "新版：要調整的參數\n",
        "1. 森林大小-預設值＝10 n_estimators=10  (api沒更新到) \\\n",
        "2. max_depth:最大深度\n",
        "\n",
        "(隨機森林regressor:取森林投票平均值) \\\n",
        "每棵樹都放棄一點資料,如每棵決策樹都只取90%\b\b而不是吃全部, \\\n",
        "達到每棵樹都略有不同,最終投票的結果才會有意義\n",
        "\n",
        "調整參數的方法：$\\color{lime}{交叉驗證\\ Cross \\ \\ Validation}$ \\\n",
        "(視資料決定要用哪種演算法：決策樹、隨機森林...)\n",
        "\n",
        "pandas 的 iloc : index location 代表該筆資料在第幾個 Row \\\n",
        "(從0起算)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7UUB_SfSVZF"
      },
      "source": [
        "y = train_df[\"Survived\"]\n",
        "# .iloc: [1st row, 2nd row, ....]\n",
        "x = datas.iloc[:len(train_df)]\n",
        "predict = datas.iloc[len(train_df):]\n",
        "# 將處理後的datas, 切割成兩份, x = x_train, predict = x_test\n",
        "predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guI52LLCGEYh"
      },
      "source": [
        "model_selection 調整參數的估算器\n",
        "[ https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection ]\n",
        "\n",
        "\n",
        "寫一組loop, 每一組參數都試一遍\n",
        "Grid Search \\\n",
        "[ https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html ] \\\n",
        "\n",
        "estimator 估算器=> ex:隨機森林分類器 \\\n",
        "param_grid: 字典或字典清單, 給一個區間讓GridSearchCV迭代找出最佳的參數 \\\n",
        "scoring: 評分標準, 這裡使用negative log loss來找到最接近0的參數, 也就是平均最短距離, negative就是評分會以負數表示\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI95b-l0K6FR"
      },
      "source": [
        "# ensemble 一起、整體 \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "clf = RandomForestClassifier()\n",
        "params = {\n",
        "    \"n_estimators\":[11, 12],\n",
        "    \"max_depth\":[5, 6]\n",
        "}\n",
        "# params = {\n",
        "#     \"n_estimators\":range(11, 151, 2),\n",
        "#     \"max_depth\":range(5, 11)\n",
        "# }\n",
        "grid = GridSearchCV(clf, params, cv=10, n_jobs=-1, scoring='neg_log_loss')\n",
        "grid.fit(x, y)\n",
        "print(grid.best_score_)\n",
        "print(grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApiJ5o3ERgg2"
      },
      "source": [
        "(cross_val_score)[ https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html ]\n",
        "\n",
        "cv=cross validation 切幾份\n",
        "交叉驗證的機制 [ https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation ] \\\n",
        "\n",
        "\n",
        "n_jobs 分工同時執行,電腦4核心就同時執行4份工\\\n",
        "預設None 單核心, 設-1則視電腦核心數決定同時跑多少工\n",
        "\n",
        "scoring 評分機制 \\\n",
        "(model evaluation documentation)\n",
        "[ https://scikit-learn.org/stable/modules/model_evaluation.html ]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixNPbHy-Q26x"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=50, max_depth=6)\n",
        "scores = cross_val_score(clf, x, y, cv=10, n_jobs=-1)\n",
        "print(scores)\n",
        "print(np.average(scores))\n",
        "clf = RandomForestClassifier(n_estimators=53, max_depth=8)\n",
        "scores = cross_val_score(clf, x, y, cv=10, n_jobs=-1, scoring='neg_log_loss')\n",
        "print(scores)\n",
        "print(np.average(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_JBQb9h0Pfc"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=53, max_depth=7)\n",
        "clf.fit(x, y)\n",
        "pre = clf.predict(predict)\n",
        "ans = pd.DataFrame({\n",
        "    \"PassengerId\":test_df[\"PassengerId\"],\n",
        "    \"Survived\":pre\n",
        "})\n",
        "ans.to_csv(\"rf.csv\", encoding=\"utf-8\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5ccT0Qx1rAA"
      },
      "source": [
        "MinMaxScaler: \\\n",
        "[ https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler ] \\\n",
        "preprocessing預處理的class\n",
        "\n",
        "將特定欄位的值做縮放固定在某個範圍,通常會收縮範圍 0 ~ 1, \\\n",
        "此題對所有欄位縮放到0 ~ 1, \\\n",
        "是為了使用KNN演算法(以 計算距離 為主的演算法), 因為此法沒有隨機性, \\\n",
        "故須先做標準化,讓features的值收縮後,大家都差不多(單位一致), \\\n",
        "此案例 Titanic中的age年紀欄位,若不收縮,會導致主宰其他欄位資訊,使結果失真\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDd5zI6W1u6O"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "datas_scale = scaler.fit_transform(datas)\n",
        "datas_scale = pd.DataFrame(datas_scale, columns=datas.columns)\n",
        "datas_scale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJohYlu4qeer"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(clf.feature_importances_,\n",
        "             columns=[\"Importance\"],\n",
        "             index=datas.columns).sort_values(by=\"Importance\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uKnjckSsC1L"
      },
      "source": [
        "dt = clf.estimators_[1]\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import plot_tree\n",
        "plt.figure(figsize=(14, 14))\n",
        "plot_tree(dt, \n",
        "     feature_names=datas.columns, \n",
        "     class_names=[\"Dead\", \"Alive\"], \n",
        "     max_depth=3,\n",
        "     filled=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7iCVBfwt1r3"
      },
      "source": [
        "### female、male存活『人數』\n",
        "用Seaborn\n",
        "\n",
        "知道哪些特徵很重要,才知道畫哪些圖\n",
        "    1. 散佈圖(連續數值...scatter)\n",
        "    2. 數量圖\n",
        "    3. 區間圖\n",
        "\n",
        "matplotlib參數設定 \\\n",
        "tick：xticks、yticks x軸及y軸上的資料間隔 \\\n",
        "rotation: 間隔的label字太長,要旋轉\n",
        "[ https://matplotlib.org/stable/gallery/ticks_and_spines/ticklabels_rotation.html ] \\\n",
        "legend: 圖表的簡要label說明 \\\n",
        "\n",
        "pd.cut():將資料的區間切成幾等份\n",
        "[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html ]\\\n",
        "\n",
        "seaborn.histplot(): 用不到,因為此方法的hue只有定義顏色,無法設定欄位\n",
        "[https://seaborn.pydata.org/generated/seaborn.histplot.html#seaborn.histplot ]\n",
        "\n",
        "sort_values(): by = 欄位 or row, axis:\b 1, 0\n",
        "[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html ]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLHrNnuhuAZY"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(y=train_df[\"Sex\"], hue=train_df[\"Survived\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSnD3dFDu6qw"
      },
      "source": [
        "# sns.histplot(train_df[\"Fare\"])\n",
        "# print(train_df[\"Fare\"])\n",
        "c = pd.cut(train_df[\"Fare\"], bins=10)\n",
        "def beautify(s):\n",
        "    return str(s)[1:-1].replace(\",\", \" ~ \")\n",
        "b = c.apply(beautify)\n",
        "plt.figure(figsize=(20, 10))\n",
        "sns.countplot(x=b, hue=train_df[\"Survived\"])\n",
        "plt.xticks(rotation=30)\n",
        "plt.legend(loc=1)\n",
        "plt.title(\"Fare Plot圖\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhIWbyHVz7CR"
      },
      "source": [
        "c = pd.cut(train_df[\"Age\"], bins=10)\n",
        "def beautify(s):\n",
        "    return str(s)[1:-1].replace(\",\", \" ~ \")\n",
        "b = c.apply(beautify)\n",
        "plt.figure(figsize=(20, 10))\n",
        "sns.countplot(x=b, hue=train_df[\"Survived\"])\n",
        "plt.xticks(rotation=30)\n",
        "plt.legend(loc=1)\n",
        "plt.title(\"Fare Plot\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5L5qwTv4jae"
      },
      "source": [
        "# 收縮後的資料拆分成x_train, x_test\n",
        "x_scale = datas_scale.iloc[:len(train_df)]\n",
        "predict_scale = datas_scale.iloc[len(train_df):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18WeeJc74fen"
      },
      "source": [
        "用另一種演算法比較\n",
        "KNN (K-nearest Neighbors) 找最近鄰\n",
        "\n",
        "[ https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html ]\n",
        "\n",
        "log_loss越接近0越好,越小越好 \\\n",
        "相反地, neg_log_loss 為 -log_loss, 故越接近0越好,越大越好\n",
        "\n",
        "KNN演算法\n",
        "[ https://medium.com/@NorthBei/machine-learning-knn%E5%88%86%E9%A1%9E%E6%BC%94%E7%AE%97%E6%B3%95-b3e9b5aea8df ]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LXmTbVX4rEq"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "clf = KNeighborsClassifier()\n",
        "params = {\n",
        "    \"n_neighbors\":range(5, 200)\n",
        "}\n",
        "grid = GridSearchCV(clf, params, cv=10, n_jobs=-1, scoring='neg_log_loss')\n",
        "grid.fit(x_scale, y)\n",
        "print(grid.best_score_)\n",
        "print(grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qklN-DdR5QFx"
      },
      "source": [
        "clf = KNeighborsClassifier(n_neighbors=11)\n",
        "# 老師嘗試最好的成績是：11\n",
        "clf.fit(x_scale, y)\n",
        "pre = clf.predict(predict_scale)\n",
        "ans = pd.DataFrame({\n",
        "    \"PassengerId\":test_df[\"PassengerId\"],\n",
        "    \"Survived\":pre\n",
        "})\n",
        "print(ans)\n",
        "ans.to_csv(\"knn.csv\", encoding=\"utf-8\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bsyXLw7j_h_"
      },
      "source": [
        "RamdomForest vs. KNeighbors\n",
        "\n",
        "資料的準備、資料的整理, 是最重要的, 是我的天花板, \\\n",
        "演算法只是幫助逼近我想要的結果 \\\n",
        "不同\\相同演算法 不應該差太多(1~2% ok)\n",
        "\n",
        "1. 吃的資料量 \\\n",
        "    RF: 全部 \\\n",
        "    KNN: 附近k個 (局部)=> 適用資料量較少時 ex:推薦系統 \\\n",
        "\n",
        "2. 調整參數\n",
        "    RF: 難度較高, 要靠賽,要不斷try, 找出最穩定的參數\n",
        "    KNN: 較穩定, 沒有懸念\n",
        "\n",
        "3. 對於特徵的重視程度- 特徵係數(重要性)：\n",
        "    RF: 有。欄位重要程度有差別\n",
        "    KNN: 無 。套公式算距離,每個距離都一視同仁, 沒有對每個特徵做分層\n",
        "\n",
        "4. (線性)相關係數：\n",
        "\n",
        "    ex:feature_importances_\n",
        "\n",
        "[https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html ]\n",
        "\n",
        "\n"
      ]
    }
  ]
}